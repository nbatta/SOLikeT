{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solike.clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[prior] *WARNING* No sampled parameters requested! This will fail for non-mock samplers.\n",
      "[camb] *local* CAMB not found at /Users/nab/Repos/cobaya_modules/code/CAMB\n",
      "[camb] Importing *global* CAMB.\n",
      "[pks] Initialized external likelihood.\n",
      "[camb] *ERROR* hubble_units and k_hunit must be Falsefor consistency\n"
     ]
    },
    {
     "ename": "LoggedError",
     "evalue": "hubble_units and k_hunit must be Falsefor consistency",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLoggedError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7ccfbea84ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     'modules': modules_path}\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcobaya\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel_fiducial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_fiducial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'loglike'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fiducial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'As'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3e-9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ns'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.96\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Declare our desired theory product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/model.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(info, stop_at_error)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpath_install\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path_install\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mtiming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdated_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_timing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mstop_at_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo_stop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstop_at_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstop_at_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, info_params, info_likelihood, info_prior, info_theory, path_install, timing, allow_renames, stop_at_error, post, prior_parameterization)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_theory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_dependencies_and_providers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_measured_speeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/model.py\u001b[0m in \u001b[0;36m_set_dependencies_and_providers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mneed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                         conditional_requirements = _tidy_requirements(\n\u001b[0;32m--> 608\u001b[0;31m                             \u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mneed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mneed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                         )\n\u001b[1;32m    610\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_needs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/theories/camb/camb.py\u001b[0m in \u001b[0;36mneeds\u001b[0;34m(self, **requirements)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;31m# different likelihoods. Store results without Hubble units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hubble_units\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"k_hunit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                     raise LoggedError(self.log, \"hubble_units and k_hunit must be False\"\n\u001b[0m\u001b[1;32m    357\u001b[0m                                                 \"for consistency\")\n\u001b[1;32m    358\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hubble_units\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLoggedError\u001b[0m: hubble_units and k_hunit must be Falsefor consistency"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "fiducial_params = {\n",
    "    'ombh2': 0.02225, 'omch2': 0.1198, 'H0': 67.3, 'tau': 0.06,\n",
    "    'As': 2.2e-9, 'ns': 0.96,\n",
    "    'mnu': 0.06, 'nnu': 3.046, 'num_massive_neutrinos': 1}\n",
    "l_max = 1000\n",
    "zarr = np.linspace(0,2,41)\n",
    "modules_path = '/Users/nab/Repos/cobaya_modules/'\n",
    "\n",
    "def pk(_theory={'Pk_interpolator': {'z': np.linspace(0,4,41), 'k_max': 100.0, 'nonlinear': True,'hubble_units': True,'k_hunit': True, 'vars_pairs': [['delta_nonu','delta_nonu']]}}):\n",
    "    #print (_theory.get_Pk_interpolator())\n",
    "    Pk_interpolator = _theory.get_Pk_interpolator()['delta_nonu_delta_nonu'].P\n",
    "    k = np.logspace(-3,1,100)\n",
    "    return Pk_interpolator(0.0,k)\n",
    "\n",
    "info_fiducial = {\n",
    "    'params': fiducial_params,\n",
    "    'likelihood': {'pks': pk},\n",
    "    'theory': {'camb':{'extra_args':{\"accurate_massive_neutrino_transfers\": True,\n",
    "                                                   \"redshifts\": np.linspace(0,2,41), \"nonlinear\": False,\n",
    "                                                   \"kmax\": 10., \"dark_energy_model\":\"ppf\"}}\n",
    "              },\n",
    "    'modules': modules_path}\n",
    "\n",
    "from cobaya.model import get_model\n",
    "model_fiducial = get_model(info_fiducial)\n",
    "print ('loglike', model_fiducial.loglike({'As': 3e-9, 'ns':0.96}))\n",
    "# Declare our desired theory product\n",
    "# (there is no cosmological likelihood doing it for us)\n",
    "model_fiducial.likelihood.theory.needs(Cl={'tt': l_max},\n",
    "                                       Pk_interpolator={'z': np.linspace(0,2,41), 'k_max': 5.0,\n",
    "                                                        'nonlinear': False,'hubble_units': True,'k_hunit': True,\n",
    "                                                        'vars_pairs': [['delta_tot','delta_tot']]},\n",
    "                                       H={'z': np.linspace(0,2,41)})#,\n",
    "                                       #extra_args={\"accurate_massive_neutrino_transfers\": True,\n",
    "                                       #            \"redshifts\": np.linspace(0,4,41), \"nonlinear\": False,\n",
    "                                       #            \"kmax\": 10., \"dark_energy_model\":\"ppf\"})\n",
    "# Compute and extract the CMB power spectrum\n",
    "# (In muK^-2, without l(l+1)/(2pi) factor)\n",
    "# notice the empty dictionary below: all parameters are fixed\n",
    "model_fiducial.logposterior({})\n",
    "Cls = model_fiducial.likelihood.theory.get_Cl(ell_factor=False)\n",
    "print(model_fiducial.likelihood.theory.requested())\n",
    "Pk_interpolator = model_fiducial.likelihood.theory.get_Pk_interpolator()['delta_nonu_delta_nonu'].P#(0,k_max=5)\n",
    "k = np.logspace(-4,np.log10(5),200)\n",
    "pks = Pk_interpolator(zarr,k)\n",
    "Ez = model_fiducial.likelihood.theory.get_H(zarr) / model_fiducial.likelihood.theory.get_param('H0')\n",
    "om = (model_fiducial.likelihood.theory.get_param('omch2') + model_fiducial.likelihood.theory.get_param('ombh2'))/ ((model_fiducial.likelihood.theory.get_param('H0')/100.)**2)\n",
    "print (pks.shape,Ez.shape)\n",
    "import solike.clusters.massfunc as mf\n",
    "hmf = mf.HMF(om,Ez,pk=pks,kh=k,zarr=zarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solike import ClusterLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prior] *WARNING* No sampled parameters requested! This will fail for non-mock samplers.\n",
      "[camb] Importing *global* CAMB.\n",
      "mock catalog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fiducial_params = {\n",
    "    'ombh2': 0.02225, 'omch2': 0.1198, 'H0': 67.3, 'tau': 0.06,\n",
    "    'As': 2.2e-9, 'ns': 0.96,\n",
    "    'mnu': 0.06, 'nnu': 3.046, 'num_massive_neutrinos': 1}\n",
    "\n",
    "info_fiducial = {\n",
    "    'params': fiducial_params,\n",
    "    'likelihood': {'solike.ClusterLikelihood' : {'stop_at_error': True}},\n",
    "    'theory': {'camb':{'extra_args':{\"accurate_massive_neutrino_transfers\": True,\n",
    "                                                   \"redshifts\": np.linspace(0,2,41), \"nonlinear\": False,\n",
    "                                                   \"kmax\": 10., \"dark_energy_model\":\"ppf\"}}\n",
    "              }}\n",
    "\n",
    "from cobaya.model import get_model\n",
    "model_fiducial = get_model(info_fiducial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = model_fiducial.likelihood['solike.ClusterLikelihood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[solike.clusterlikelihood] *ERROR* Error at evaluation: TypeError(\"Prob_per_cluster() missing 1 required positional argument: 'tsz_signal_err'\")\n"
     ]
    },
    {
     "ename": "LoggedError",
     "evalue": "Error at evaluation: TypeError(\"Prob_per_cluster() missing 1 required positional argument: 'tsz_signal_err'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/repositories/cobaya/cobaya/theory.py\u001b[0m in \u001b[0;36mcheck_cache_and_compute\u001b[0;34m(self, dependency_params, want_derived, cached, **params_values_dict)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_derived\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams_values_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/likelihood.py\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self, state, want_derived, **params_values_dict)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m  \u001b[0;31m# in case of exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_derived\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mderived\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams_values_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwant_derived\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/likelihoods/solike/poisson.py\u001b[0m in \u001b[0;36mlogp\u001b[0;34m(self, **params_values)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mn_expected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_n_expected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_expected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repositories/likelihoods/solike/poisson_data.py\u001b[0m in \u001b[0;36mloglike\u001b[0;34m(self, rate_fn, n_expected)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mrate_densities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Prob_per_cluster() missing 1 required positional argument: 'tsz_signal_err'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLoggedError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cf99910a0158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_fiducial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repositories/cobaya/cobaya/model.py\u001b[0m in \u001b[0;36mloglikes\u001b[0;34m(self, params_values, return_derived, make_finite, cached, _no_check)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         result = self.logps(\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0minput_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_derived\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_derived\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         )\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_derived\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/model.py\u001b[0m in \u001b[0;36mlogps\u001b[0;34m(self, input_params, return_derived, cached, make_finite)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             compute_success = component.check_cache_and_compute(\n\u001b[0;32m--> 267\u001b[0;31m                 \u001b[0mwant_derived\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_derived\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepend_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             )\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/theory.py\u001b[0m in \u001b[0;36mcheck_cache_and_compute\u001b[0;34m(self, dependency_params, want_derived, cached, **params_values_dict)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_at_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mLoggedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error at evaluation: %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                     self.log.debug(\n",
      "\u001b[0;31mLoggedError\u001b[0m: Error at evaluation: TypeError(\"Prob_per_cluster() missing 1 required positional argument: 'tsz_signal_err'\")"
     ]
    }
   ],
   "source": [
    "model_fiducial.loglikes({})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'camb' object has no attribute '_current_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c00deb26c8de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_HMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repositories/likelihoods/solike/clusters/clusters.py\u001b[0m in \u001b[0;36m_get_HMF\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_HMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mPk_interpolator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_Pk_interpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delta_nonu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"delta_nonu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mpks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPk_interpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mEz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_H\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzarr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"H0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/cobaya/cobaya/theories/_cosmo/boltzmannbase.py\u001b[0m in \u001b[0;36mget_Pk_interpolator\u001b[0;34m(self, var_pair, nonlinear, extrap_kmax)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mnonlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Pk_interpolator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextrap_kmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_Pk_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnonlinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'camb' object has no attribute '_current_state'"
     ]
    }
   ],
   "source": [
    "like._get_HMF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mock catalog\n"
     ]
    }
   ],
   "source": [
    "surveydata = like._get_catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveydata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _get_catalog():\n",
    "    catalog = Survey.SurveyData(self.data_path, self.data_name)\n",
    "    return catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_per_cluster(self, HMF, cluster_props, param_vals):\n",
    "    # c_z, c_zerr, c_y, c_yerr = cluster_props\n",
    "    tempz = cluster_props[0, :]\n",
    "    zind = np.argsort(tempz)\n",
    "    tempz = 0.\n",
    "    c_z = cluster_props[0, zind]\n",
    "    c_zerr = cluster_props[1, zind]\n",
    "    c_y = cluster_props[2, zind]\n",
    "    c_yerr = cluster_props[3, zind]\n",
    "\n",
    "    Marr = np.outer(int_HMF.M.copy(), np.ones([len(c_z)]))\n",
    "    zarr = np.outer(np.ones([len(int_HMF.M.copy())]), c_z)\n",
    "\n",
    "    if (c_zerr.any() > 0):\n",
    "        # FIX THIS\n",
    "        z_arr = np.arange(-3.*c_zerr, (3.+0.1)*c_zerr, c_zerr) + c_z\n",
    "        Pfunc_ind = self.Pfunc_per_zarr(int_HMF.M.copy(), z_arr, c_y, c_yerr, int_HMF, param_vals)\n",
    "        M200 = int_HMF.cc.Mass_con_del_2_del_mean200(int_HMF.M.copy(), 500, c_z)  # FIX THIS?\n",
    "        dn_dzdm = dn_dzdm_int(z_arr, np.log10(int_HMF.M.copy()))\n",
    "        N_z_ind = np.trapz(dn_dzdm*Pfunc_ind, dx=np.diff(M200, axis=0), axis=0)\n",
    "        N_per = np.trapz(N_z_ind*gaussian(z_arr, c_z, c_zerr), dx=np.diff(z_arr))\n",
    "        ans = N_per\n",
    "    else:\n",
    "        Pfunc_ind = self.Pfunc_per(Marr, zarr, c_y, c_yerr, param_vals)\n",
    "        dn_dzdm = HMF.dn_dzdm(c_z, np.log10(int_HMF.M.copy()))\n",
    "        M200 = int_HMF.M200_int(c_z, int_HMF.M.copy())\n",
    "        N_z_ind = np.trapz(dn_dzdm*Pfunc_ind, dx=np.diff(M200, axis=0), axis=0)\n",
    "        ans = N_z_ind\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_per_cluster(HMF, z, y, param_vals):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
